{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "training_file_path = \"./IA2-train.csv\"\n",
    "validation_file_path = \"./IA2-dev.csv\"\n",
    "\n",
    "df_train = data_preprocessing(training_file_path)\n",
    "df_val = data_preprocessing(validation_file_path)\n",
    "\n",
    "df_train, df_val = feature_normalization(df_train, df_val)\n",
    "\n",
    "# separate X and Y\n",
    "X_train, Y_train = separate_X_Y(df_train)\n",
    "X_val, Y_val = separate_X_Y(df_val)\n",
    "\n",
    "\n",
    "def data_preprocessing(csv_file_path):\n",
    "  '''\n",
    "  :param csv_file_path: str, training or validation csv file path\n",
    "  :return: processed df\n",
    "  '''\n",
    "  df = pd.read_csv(csv_file_path)\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "def separate_X_Y(df):\n",
    "  '''\n",
    "  :param df: processed data\n",
    "  :return: X: np 2d array, N*d\n",
    "           Y: np 1d array, 1*N\n",
    "  '''\n",
    "  if 'Response' in df:\n",
    "    df_Y = df['Response']\n",
    "    df_X = df.drop('Response', axis=1)\n",
    "    return df_X.to_numpy(), df_Y.to_numpy()\n",
    "  else:\n",
    "    return df.to_numpy(), None\n",
    "\n",
    "\n",
    "def feature_normalization(df_train, df_val):\n",
    "  '''\n",
    "  :param df_train: df, training data after preprocessing\n",
    "  :param df_val: df, validation or test data after preprocessing\n",
    "  :return: df_train and df_val after normalization of z score\n",
    "  '''\n",
    "\n",
    "  # apply z-score to all the columns except \"dummy\" & \"waterfront\" & \"price\"\n",
    "  columns_applied = ['Annual_Premium', 'Age', 'Vintage']\n",
    "\n",
    "  # data processing\n",
    "  # preprocess training data\n",
    "  df_applied_train = df_train[columns_applied]\n",
    "\n",
    "  train_mean = mean(df_applied_train)\n",
    "  train_std = std(df_applied_train)\n",
    "  df_z_score_train = (df_applied_train - train_mean) / train_std\n",
    "  df_train.update(df_z_score_train)\n",
    "\n",
    "  # preprocess validation data\n",
    "  df_applied_val = df_val[columns_applied]\n",
    "  df_z_score_val = (df_applied_val - train_mean) / train_std\n",
    "  df_val.update(df_z_score_val)\n",
    "\n",
    "  return df_train, df_val\n",
    "\n",
    "\n",
    "def mean(df):\n",
    "  return df.mean()\n",
    "\n",
    "def std(df):\n",
    "  return df.std()\n",
    "\n",
    "def z_score(df, mean, std):\n",
    "  return (df - mean) / std\n",
    "\n",
    "\n",
    "# calculate loss here -- loss function\n",
    "def sigmoid(z): \n",
    "  return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "def LR_l2(X, Y, iter_num, lamda, alpha):  \n",
    "    \n",
    "  # print(predict_0)\n",
    "  # print(-np.sum(predict_1 + predict_0) / X.shape[0] + lamda * np.sum((w**2)))\n",
    "\n",
    "  iter_count = 0\n",
    "  # w = np.random.rand(X.shape[1])\n",
    "  w = np.ones(X.shape[1])\n",
    "  loss_values = []\n",
    "\n",
    "  while iter_count < iter_num: # and loss_function(X, Y, w, lamda) < epsilon:\n",
    "    iter_count += 1\n",
    "    # print(delta_w(X,Y,w))\n",
    "    # print(w)\n",
    "    predict_1 = Y * np.log(y_hat(X, w))\n",
    "    predict_0 = (1 - Y) * np.log(1 - y_hat(X, w))\n",
    "    w = w + alpha * delta_w(X, Y, w)\n",
    "    w = w - alpha * lamda * w\n",
    "    loss_value = -np.sum(predict_1 + predict_0) / X.shape[0] + lamda * np.sum((w**2))\n",
    "    # print(w)\n",
    "    # print(loss_function_l2(X, Y, w, lamda))\n",
    "    loss_values.append(loss_value)\n",
    "\n",
    "  return w, loss_values\n",
    "\n",
    "def y_hat(X, w):\n",
    "  '''\n",
    "  :param X: np 2d array, N*d, the training data\n",
    "  :param w: np 1d array, 1*d, the learned parameters\n",
    "  :return: y_hat, np 1d array, 1*N, the computed y (predicted y)\n",
    "  '''\n",
    "\n",
    "  return sigmoid(np.dot(X, w))\n",
    "\n",
    "def delta_w(X, Y, w):\n",
    "  '''\n",
    "  :param X: np 2d array, N*d, training data\n",
    "  :param Y: np 1d array, 1*N, ground truth\n",
    "  :param w: np 1d array, 1*d, parameters learned for each iteration\n",
    "  :return: delta_w, gradient for MSE, used to update w for each iteration\n",
    "  '''\n",
    "\n",
    "  return 1 / Y.shape[0] * np.dot(( Y - y_hat(X, w)), X)\n",
    "\n",
    "\n",
    "# def plot_loss_vs_iter(df_iter_mse, MSE_plot_save_path, learning_rate):\n",
    "#   '''\n",
    "#   :param df_iter_mse: df, contains iteration number and MSE value\n",
    "#   :param MSE_plot_save_path: str, the file name to save the line plot\n",
    "#   :param learning_rate: the used learning rate\n",
    "#   :return: none, save lineplot to the file path\n",
    "#   '''\n",
    "\n",
    "#   plt.clf()\n",
    "#   iter_mse = sns.lineplot(data=df_iter_mse, x=\"iter\", y=\"loss\").set_title('learning rate: ' + str(learning_rate))\n",
    "#   fig_iter_mse = iter_mse.get_figure()\n",
    "#   fig_iter_mse.show()\n",
    "#   # fig_iter_mse.savefig(MSE_plot_save_path)\n",
    "\n",
    "\n",
    "def plot_accuracy_vs_lamda(df_lamda_accuracy, accuracy_plot_save_path, train_or_val):\n",
    "  '''\n",
    "  :param df_lamda_accuracy: df, contains accuracy and lamda value (regularization term)\n",
    "  :param accuracy_plot_save_path: str, the file name to save the line plot\n",
    "  :param regularization_term: the used regularization term\n",
    "  :return: none, save lineplot to the file path\n",
    "  '''\n",
    "\n",
    "  plt.clf()\n",
    "  lamda_accuracy = sns.lineplot(data=df_lamda_accuracy, x=\"regularization_lamda\", y=\"accuracy\").set_title(train_or_val)\n",
    "  fig_lamda_accuracy = lamda_accuracy.get_figure()\n",
    "  fig_lamda_accuracy.savefig(accuracy_plot_save_path)\n",
    "\n",
    "\n",
    "def plot_w_zeros_vs_lamda(df_lamda_w_zeros, w_zeros_plot_save_path):\n",
    "  '''\n",
    "  :param df_lamda_accuracy: df, contains accuracy and lamda value (regularization term)\n",
    "  :param accuracy_plot_save_path: str, the file name to save the line plot\n",
    "  :param regularization_term: the used regularization term\n",
    "  :return: none, save lineplot to the file path\n",
    "  '''\n",
    "\n",
    "  plt.clf()\n",
    "  lamda_w_zeros = sns.lineplot(data=df_lamda_w_zeros, x=\"regularization_lamda\", y=\"w_zeros\").set_title(\"weights_zeros_vs_lamda\")\n",
    "  fig_lamda_w_zeros = lamda_w_zeros.get_figure()\n",
    "  fig_lamda_w_zeros.savefig(w_zeros_plot_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------\n",
      "lamda =  0.0001\n",
      "Index(['Previously_Insured', 'Vehicle_Damage', 'dummy', 'Driving_License',\n",
      "       'Policy_Sales_Channel_26'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "lamda =  0.001\n",
      "Index(['Previously_Insured', 'Vehicle_Damage', 'dummy', 'Driving_License',\n",
      "       'Policy_Sales_Channel_26'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "lamda =  0.01\n",
      "Index(['Previously_Insured', 'Vehicle_Damage', 'dummy', 'Driving_License',\n",
      "       'Policy_Sales_Channel_26'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "lamda =  0.1\n",
      "Index(['Previously_Insured', 'Vehicle_Damage', 'Policy_Sales_Channel_152',\n",
      "       'Vehicle_Age_1', 'dummy'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "lamda =  1.0\n",
      "Index(['Previously_Insured', 'Vehicle_Damage', 'Vehicle_Age_1',\n",
      "       'Policy_Sales_Channel_152', 'Age'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "lamda =  10.0\n",
      "Index(['Vehicle_Damage', 'Previously_Insured', 'Age', 'Vehicle_Age_1',\n",
      "       'Policy_Sales_Channel_152'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "lamda =  100.0\n",
      "Index(['Policy_Sales_Channel_163', 'Policy_Sales_Channel_11',\n",
      "       'Policy_Sales_Channel_9', 'Policy_Sales_Channel_8',\n",
      "       'Policy_Sales_Channel_7'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "lamda =  1000.0\n",
      "Index(['Policy_Sales_Channel_163', 'Policy_Sales_Channel_11',\n",
      "       'Policy_Sales_Channel_9', 'Policy_Sales_Channel_8',\n",
      "       'Policy_Sales_Channel_7'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "lamda =  10000.0\n",
      "Index(['Policy_Sales_Channel_163', 'Policy_Sales_Channel_11',\n",
      "       'Policy_Sales_Channel_9', 'Policy_Sales_Channel_8',\n",
      "       'Policy_Sales_Channel_7'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "lamda =  100000.0\n",
      "Index(['Policy_Sales_Channel_163', 'Policy_Sales_Channel_11',\n",
      "       'Policy_Sales_Channel_9', 'Policy_Sales_Channel_8',\n",
      "       'Policy_Sales_Channel_7'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-62be4673b10e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m }\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mdf_w_zeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mplot_w_zeros_vs_lamda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_w_zeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_zeros_plot_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_36/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_36/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_36/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "iter_num = math.pow(10, 4)\n",
    "# epsilon = math.pow(10, -6)\n",
    "# learning rate\n",
    "alpha = math.pow(10, -2)\n",
    "# regularization parameter\n",
    "# lamda = math.pow(10, -1)\n",
    "\n",
    "# # Model training\n",
    "# w, loss_values = LR_l2(X_train, Y_train, iter_num, lamda, alpha)\n",
    "# print(loss_values[-1])\n",
    "\n",
    "# y_predicted = [1 if x >= 0.5 else 0 for x in y_hat(X_val, w)]\n",
    "\n",
    "# if Y_val is not None:\n",
    "#     accuracy = np.count_nonzero(Y_val == y_predicted) / Y_val.shape[0]\n",
    "#     print(accuracy)\n",
    "\n",
    "w_zeros_plot_save_path = \"./plots/w_zeros.jpg\"\n",
    "zeros = []\n",
    "\n",
    "for i in range(-4, 6):\n",
    "    iter_num = math.pow(10, 4)\n",
    "    # learning rate\n",
    "    alpha = math.pow(10, -2)\n",
    "    # regularization parameter\n",
    "    lamda = math.pow(10, i)\n",
    "\n",
    "    # Model training\n",
    "    w, _ = LR_l2(X_train, Y_train, iter_num, lamda, alpha)\n",
    "\n",
    "    # if i in range(-4, -1):\n",
    "    w_absolute = np.absolute(w)\n",
    "    top_value_indice = w_absolute.argsort()[-5:][::-1]\n",
    "    top_5_feature_names = df_train.columns[top_value_indice]\n",
    "    print(\"--------------------\")\n",
    "    print(\"lamda = \", lamda)\n",
    "    print(top_5_feature_names)\n",
    "\n",
    "    \n",
    "    n_zeros = np.count_nonzero(w==0)\n",
    "    zeros.append(n_zeros)\n",
    "\n",
    "dict_w = {\n",
    "    'regularization_lamda': list(range(-4,4)),\n",
    "    'w_zeros': zeros\n",
    "}\n",
    "\n",
    "df_w_zeros = pd.DataFrame(dict_w)\n",
    "plot_w_zeros_vs_lamda(df_w_zeros, w_zeros_plot_save_path)\n",
    "\n",
    "\n",
    "# dict = {\n",
    "#     'y_predicted': y_predicted,\n",
    "#     'Y_val': Y_val\n",
    "# }\n",
    "# df_pred = pd.DataFrame(dict)\n",
    "# df_pred.to_csv('./pred.csv')\n",
    "\n",
    "\n",
    "\n",
    "# acc_train_plot_save_path = './plots/train_acc.jpg'\n",
    "# acc_val_plot_save_path = './plots/val_acc.jpg'\n",
    "\n",
    "# acc_train = []\n",
    "# acc_val = []\n",
    "\n",
    "# for i in range(-3,4):\n",
    "#     iter_num = math.pow(10, 4)\n",
    "#     # learning rate\n",
    "#     alpha = math.pow(10, -2)\n",
    "#     # regularization parameter\n",
    "#     lamda = math.pow(10, i)\n",
    "\n",
    "#     # Model training\n",
    "#     w, _ = LR_l2(X_train, Y_train, iter_num, lamda, alpha)\n",
    "\n",
    "#     y_predicted_train = [1 if x >= 0.5 else 0 for x in y_hat(X_train, w)]\n",
    "#     y_predicted = [1 if x >= 0.5 else 0 for x in y_hat(X_val, w)]\n",
    "\n",
    "#     accuracy_train = np.count_nonzero(Y_train == y_predicted_train) / Y_train.shape[0]\n",
    "#     accuracy_val = np.count_nonzero(Y_val == y_predicted) / Y_val.shape[0]\n",
    "\n",
    "#     acc_train.append(accuracy_train)\n",
    "#     acc_val.append(accuracy_val)\n",
    "\n",
    "\n",
    "# dict_train = {\n",
    "#     'regularization_lamda': list(range(-3,4)),\n",
    "#     'accuracy': acc_train\n",
    "# }\n",
    "# dict_val = {\n",
    "#     'regularization_lamda': list(range(-3,4)),\n",
    "#     'accuracy': acc_val\n",
    "# }\n",
    "\n",
    "# df_train_acc = pd.DataFrame(dict_train)\n",
    "# df_val_acc = pd.DataFrame(dict_val)\n",
    "\n",
    "# plot_accuracy_vs_lamda(df_train_acc, acc_train_plot_save_path, \"training_accuracy\")\n",
    "# plot_accuracy_vs_lamda(df_val_acc, acc_val_plot_save_path, \"validation_accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}