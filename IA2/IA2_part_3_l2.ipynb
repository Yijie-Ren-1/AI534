{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot(df_lamda_w_zeros, w_zeros_plot_save_path, y_name):\n",
    "  plt.clf()\n",
    "  lamda_w_zeros = sns.histplot(data=df_lamda_w_zeros, y=y_name).set_title(\"weights_zeros_vs_lamda\")\n",
    "  fig_lamda_w_zeros = lamda_w_zeros.get_figure()\n",
    "  fig_lamda_w_zeros.savefig(w_zeros_plot_save_path)\n",
    "\n",
    "\n",
    "\n",
    "def data_preprocessing(csv_file_path):\n",
    "  '''\n",
    "  :param csv_file_path: str, training or validation csv file path\n",
    "  :return: processed df\n",
    "  '''\n",
    "  df = pd.read_csv(csv_file_path)\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "def separate_X_Y(df):\n",
    "  '''\n",
    "  :param df: processed data\n",
    "  :return: X: np 2d array, N*d\n",
    "           Y: np 1d array, 1*N\n",
    "  '''\n",
    "  if 'Response' in df:\n",
    "    df_Y = df['Response']\n",
    "    df_X = df.drop('Response', axis=1)\n",
    "    return df_X.to_numpy(), df_Y.to_numpy()\n",
    "  else:\n",
    "    return df.to_numpy(), None\n",
    "\n",
    "\n",
    "def feature_normalization(df_train, df_val):\n",
    "  '''\n",
    "  :param df_train: df, training data after preprocessing\n",
    "  :param df_val: df, validation or test data after preprocessing\n",
    "  :return: df_train and df_val after normalization of z score\n",
    "  '''\n",
    "\n",
    "  # apply z-score to all the columns except \"dummy\" & \"waterfront\" & \"price\"\n",
    "  columns_applied = ['Annual_Premium', 'Age', 'Vintage']\n",
    "\n",
    "  # data processing\n",
    "  # preprocess training data\n",
    "  df_applied_train = df_train[columns_applied]\n",
    "\n",
    "  train_mean = mean(df_applied_train)\n",
    "  train_std = std(df_applied_train)\n",
    "  df_z_score_train = (df_applied_train - train_mean) / train_std\n",
    "  df_train.update(df_z_score_train)\n",
    "\n",
    "  # preprocess validation data\n",
    "  df_applied_val = df_val[columns_applied]\n",
    "  df_z_score_val = (df_applied_val - train_mean) / train_std\n",
    "  df_val.update(df_z_score_val)\n",
    "\n",
    "  return df_train, df_val\n",
    "\n",
    "\n",
    "def mean(df):\n",
    "  return df.mean()\n",
    "\n",
    "def std(df):\n",
    "  return df.std()\n",
    "\n",
    "def z_score(df, mean, std):\n",
    "  return (df - mean) / std\n",
    "\n",
    "\n",
    "# calculate loss here -- loss function\n",
    "def sigmoid(z): \n",
    "  return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "def LR_l2(X, Y, iter_num, lamda, alpha):  \n",
    "    \n",
    "  # print(predict_0)\n",
    "  # print(-np.sum(predict_1 + predict_0) / X.shape[0] + lamda * np.sum((w**2)))\n",
    "\n",
    "  iter_count = 0\n",
    "  # w = np.random.rand(X.shape[1])\n",
    "  w = np.ones(X.shape[1])\n",
    "  loss_values = []\n",
    "\n",
    "  while iter_count < iter_num: # and loss_function(X, Y, w, lamda) < epsilon:\n",
    "    iter_count += 1\n",
    "    # print(delta_w(X,Y,w))\n",
    "    # print(w)\n",
    "    predict_1 = Y * np.log(y_hat(X, w))\n",
    "    predict_0 = (1 - Y) * np.log(1 - y_hat(X, w))\n",
    "    w = w + alpha * delta_w(X, Y, w)\n",
    "    w = w - alpha * lamda * w\n",
    "    loss_value = -np.sum(predict_1 + predict_0) / X.shape[0] + lamda * np.sum((w**2))\n",
    "    # print(w)\n",
    "    # print(loss_function_l2(X, Y, w, lamda))\n",
    "    loss_values.append(loss_value)\n",
    "\n",
    "  return w, loss_values\n",
    "\n",
    "def y_hat(X, w):\n",
    "  '''\n",
    "  :param X: np 2d array, N*d, the training data\n",
    "  :param w: np 1d array, 1*d, the learned parameters\n",
    "  :return: y_hat, np 1d array, 1*N, the computed y (predicted y)\n",
    "  '''\n",
    "\n",
    "  return sigmoid(np.dot(X, w))\n",
    "\n",
    "def delta_w(X, Y, w):\n",
    "  '''\n",
    "  :param X: np 2d array, N*d, training data\n",
    "  :param Y: np 1d array, 1*N, ground truth\n",
    "  :param w: np 1d array, 1*d, parameters learned for each iteration\n",
    "  :return: delta_w, gradient for MSE, used to update w for each iteration\n",
    "  '''\n",
    "\n",
    "  return 1 / Y.shape[0] * np.dot(( Y - y_hat(X, w)), X)\n",
    "\n",
    "\n",
    "# def plot_loss_vs_iter(df_iter_mse, MSE_plot_save_path, learning_rate):\n",
    "#   '''\n",
    "#   :param df_iter_mse: df, contains iteration number and MSE value\n",
    "#   :param MSE_plot_save_path: str, the file name to save the line plot\n",
    "#   :param learning_rate: the used learning rate\n",
    "#   :return: none, save lineplot to the file path\n",
    "#   '''\n",
    "\n",
    "#   plt.clf()\n",
    "#   iter_mse = sns.lineplot(data=df_iter_mse, x=\"iter\", y=\"loss\").set_title('learning rate: ' + str(learning_rate))\n",
    "#   fig_iter_mse = iter_mse.get_figure()\n",
    "#   fig_iter_mse.show()\n",
    "#   # fig_iter_mse.savefig(MSE_plot_save_path)\n",
    "\n",
    "\n",
    "def plot_accuracy_vs_lamda(df_lamda_accuracy, accuracy_plot_save_path, train_or_val):\n",
    "  '''\n",
    "  :param df_lamda_accuracy: df, contains accuracy and lamda value (regularization term)\n",
    "  :param accuracy_plot_save_path: str, the file name to save the line plot\n",
    "  :param regularization_term: the used regularization term\n",
    "  :return: none, save lineplot to the file path\n",
    "  '''\n",
    "\n",
    "  plt.clf()\n",
    "  lamda_accuracy = sns.lineplot(data=df_lamda_accuracy, x=\"regularization_lamda\", y=\"accuracy\").set_title(train_or_val)\n",
    "  fig_lamda_accuracy = lamda_accuracy.get_figure()\n",
    "  fig_lamda_accuracy.savefig(accuracy_plot_save_path)\n",
    "\n",
    "\n",
    "def plot_w_zeros_vs_lamda(df_lamda_w_zeros, w_zeros_plot_save_path):\n",
    "  '''\n",
    "  :param df_lamda_accuracy: df, contains accuracy and lamda value (regularization term)\n",
    "  :param accuracy_plot_save_path: str, the file name to save the line plot\n",
    "  :param regularization_term: the used regularization term\n",
    "  :return: none, save lineplot to the file path\n",
    "  '''\n",
    "\n",
    "  plt.clf()\n",
    "  lamda_w_zeros = sns.lineplot(data=df_lamda_w_zeros, x=\"regularization_lamda\", y=\"w_zeros\").set_title(\"weights_zeros_vs_lamda\")\n",
    "  fig_lamda_w_zeros = lamda_w_zeros.get_figure()\n",
    "  fig_lamda_w_zeros.savefig(w_zeros_plot_save_path)\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "  df['Annual_Premium'] = pd.cut(df['Annual_Premium'],[-100,10000,15000,20000,25000,30000,35000,40000,50000,1000000],labels=list(range(0,9)))\n",
    "  # df['Age'] = df['Age'].map(pd.qcut(df['Age'].value_counts(), 20, labels=list(range(0,20))))\n",
    "  # df['Vintage'] = df['Vintage'].map(pd.qcut(df['Vintage'].value_counts(), 8, labels=list(range(0,8))))\n",
    "  df['Age'] = pd.cut(df['Age'],[-100,28,40,45,50,60,10000],labels=[0,1,2,3,4,5])\n",
    "  # df['Annual_Premium'] = pd.cut(df['Annual_Premium'],[-100,10000,20000,30000,40000,50000,1000000],labels=[0,1,2,3,4,5])\n",
    "  df['Vintage'] = pd.cut(df['Vintage'],[-100,50,100,150,200,250,10000],labels=[0,1,2,3,4,5])\n",
    "\n",
    "  age_dums = pd.get_dummies(df['Age'], prefix=\"onehot_Age\")\n",
    "  annual_premium_dums = pd.get_dummies(df['Annual_Premium'], prefix=\"onehot_Annual_Premium\")\n",
    "  vintage_dums = pd.get_dummies(df['Vintage'], prefix=\"onehot_Vintage\")\n",
    "\n",
    "  df.drop(['Age', 'Annual_Premium', 'Vintage'], axis=1, inplace=True)\n",
    "  df = pd.concat([df, age_dums, annual_premium_dums, vintage_dums], axis=1)\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "training_file_path = \"./IA2-train.csv\"\n",
    "validation_file_path = \"./IA2-dev.csv\"\n",
    "test_file_path = \"./IA2-test-small-v2-X.csv\"\n",
    "submission_filename = \"./submission.csv\"\n",
    "\n",
    "df_train = data_preprocessing(training_file_path)\n",
    "df_val = data_preprocessing(validation_file_path)\n",
    "df_test = data_preprocessing(test_file_path)\n",
    "\n",
    "# df_train, df_val = feature_normalization(df_train, df_val)\n",
    "\n",
    "df_train = feature_engineering(df_train)\n",
    "df_val = feature_engineering(df_val)\n",
    "df_test = feature_engineering(df_test)\n",
    "\n",
    "# separate X and Y\n",
    "X_train, Y_train = separate_X_Y(df_train)\n",
    "X_val, Y_val = separate_X_Y(df_val)\n",
    "X_test, _ = separate_X_Y(df_test)\n",
    "\n",
    "# df_train.insert(0, 'x_range', range(0,X_train.shape[0]))\n",
    "# df_val.insert(0, 'x_range', range(0,X_val.shape[0]))\n",
    "# df_test.insert(0, 'x_range', range(0,X_test.shape[0]))\n",
    "\n",
    "# path_train = \"./plots/train_dist\"\n",
    "# path_val = \"./plots/val_dist\"\n",
    "# path_test = \"./plots/test_dist\"\n",
    "\n",
    "# plot(df_train, path_train + '_Age.jpg', \"Age\")\n",
    "# plot(df_train, path_train + '_Annual_Premium.jpg', \"Annual_Premium\")\n",
    "# plot(df_train, path_train + '_Vintage.jpg', \"Vintage\")\n",
    "\n",
    "# plot(df_val, path_val + '_Age.jpg', \"Age\")\n",
    "# plot(df_val, path_val + '_Annual_Premium.jpg', \"Annual_Premium\")\n",
    "# plot(df_val, path_val + '_Vintage.jpg', \"Vintage\")\n",
    "\n",
    "# plot(df_test, path_test + '_Age.jpg', \"Age\")\n",
    "# plot(df_test, path_test + '_Annual_Premium.jpg', \"Annual_Premium\")\n",
    "# plot(df_test, path_test + '_Vintage.jpg', \"Vintage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.761041079785105\n0.7916\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "iter_num = math.pow(10, 4)\n",
    "# epsilon = math.pow(10, -6)\n",
    "# learning rate\n",
    "alpha = math.pow(10, -2)\n",
    "# regularization parameter\n",
    "lamda = math.pow(10, -2)\n",
    "\n",
    "# Model training\n",
    "# X_train = np.concatenate((X_train, X_val), axis=0)\n",
    "# Y_train = np.concatenate((Y_train, Y_val), axis=0)\n",
    "w, loss_values = LR_l2(X_train, Y_train, iter_num, lamda, alpha)\n",
    "print(loss_values[-1])\n",
    "\n",
    "y_predicted = [1 if x >= 0.5 else 0 for x in y_hat(X_val, w)]\n",
    "\n",
    "if Y_val is not None:\n",
    "    accuracy = np.count_nonzero(Y_val == y_predicted) / Y_val.shape[0]\n",
    "    print(accuracy)\n",
    "\n",
    "# val_pred = pd.DataFrame({'ID': list(range(0,len(y_predicted))),\n",
    "#                         'Response': y_predicted})\n",
    "# val_pred.to_csv(submission_filename, index=False)\n",
    "\n",
    "# w_zeros_plot_save_path = \"./plots/w_zeros.jpg\"\n",
    "# zeros = []\n",
    "\n",
    "# for i in range(-4, 4):\n",
    "#     iter_num = math.pow(10, 4)\n",
    "#     # learning rate\n",
    "#     alpha = math.pow(10, -3)\n",
    "#     # regularization parameter\n",
    "#     lamda = math.pow(10, i)\n",
    "\n",
    "#     # Model training\n",
    "#     w, _ = LR_l2(X_train, Y_train, iter_num, lamda, alpha)\n",
    "\n",
    "#     # if i in range(-4, -1):\n",
    "#     w_absolute = np.absolute(w)\n",
    "#     top_value_indice = w_absolute.argsort()[-5:][::-1]\n",
    "#     top_5_feature_names = df_train.columns[top_value_indice]\n",
    "#     print(\"--------------------\")\n",
    "#     print(\"lamda = \", lamda)\n",
    "#     print(top_5_feature_names)\n",
    "\n",
    "    \n",
    "#     n_zeros = np.count_nonzero(w==0)\n",
    "#     zeros.append(n_zeros)\n",
    "\n",
    "# dict_w = {\n",
    "#     'regularization_lamda': list(range(-4,4)),\n",
    "#     'w_zeros': zeros\n",
    "# }\n",
    "\n",
    "# df_w_zeros = pd.DataFrame(dict_w)\n",
    "# plot_w_zeros_vs_lamda(df_w_zeros, w_zeros_plot_save_path)\n",
    "\n",
    "\n",
    "# dict = {\n",
    "#     'y_predicted': y_predicted,\n",
    "#     'Y_val': Y_val\n",
    "# }\n",
    "# df_pred = pd.DataFrame(dict)\n",
    "# df_pred.to_csv('./pred.csv')\n",
    "\n",
    "\n",
    "\n",
    "# acc_train_plot_save_path = './plots/train_acc.jpg'\n",
    "# acc_val_plot_save_path = './plots/val_acc.jpg'\n",
    "\n",
    "# acc_train = []\n",
    "# acc_val = []\n",
    "\n",
    "# for i in range(-3,4):\n",
    "#     iter_num = math.pow(10, 4)\n",
    "#     # learning rate\n",
    "#     alpha = math.pow(10, -2)\n",
    "#     # regularization parameter\n",
    "#     lamda = math.pow(10, i)\n",
    "\n",
    "#     # Model training\n",
    "#     w, _ = LR_l2(X_train, Y_train, iter_num, lamda, alpha)\n",
    "\n",
    "#     y_predicted_train = [1 if x >= 0.5 else 0 for x in y_hat(X_train, w)]\n",
    "#     y_predicted = [1 if x >= 0.5 else 0 for x in y_hat(X_val, w)]\n",
    "\n",
    "#     accuracy_train = np.count_nonzero(Y_train == y_predicted_train) / Y_train.shape[0]\n",
    "#     accuracy_val = np.count_nonzero(Y_val == y_predicted) / Y_val.shape[0]\n",
    "\n",
    "#     acc_train.append(accuracy_train)\n",
    "#     acc_val.append(accuracy_val)\n",
    "\n",
    "\n",
    "# dict_train = {\n",
    "#     'regularization_lamda': list(range(-3,4)),\n",
    "#     'accuracy': acc_train\n",
    "# }\n",
    "# dict_val = {\n",
    "#     'regularization_lamda': list(range(-3,4)),\n",
    "#     'accuracy': acc_val\n",
    "# }\n",
    "\n",
    "# df_train_acc = pd.DataFrame(dict_train)\n",
    "# df_val_acc = pd.DataFrame(dict_val)\n",
    "\n",
    "# plot_accuracy_vs_lamda(df_train_acc, acc_train_plot_save_path, \"training_accuracy\")\n",
    "# plot_accuracy_vs_lamda(df_val_acc, acc_val_plot_save_path, \"validation_accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}